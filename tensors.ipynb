{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8cbd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm.auto import tqdm as tqdmp\n",
    "tqdmp.pandas()\n",
    "\n",
    "import cv2, os\n",
    "import skimage.io as io\n",
    "from PIL import Image\n",
    "\n",
    "# ignoring warnings\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a63eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 sync shopee-data s3://mk-dl-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb40af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'shopee-data'\n",
    "dataset = pd.read_csv(path + '/merged_with_data_tensors.csv')\n",
    "dataset = dataset.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7319465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "'''\n",
    "    It creates the pairs of images for inputs, same image label = 1, vice versa\n",
    "'''\n",
    "class ShopeeImageDataset(Dataset):\n",
    "    def __init__(self, path, training = False):\n",
    "        self.path = path\n",
    "        self.dataset = pd.read_csv(path)\n",
    "        self.dataset = self.dataset.drop(columns=['Unnamed: 0'])\n",
    "        self.setSize = self.dataset.shape[0]\n",
    "        self.training = training\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.setSize\n",
    "    def __getitem__(self, idx):\n",
    "        image1 = torch.load(self.dataset['tensor_1'][idx])\n",
    "        image2 = torch.load(self.dataset['tensor_2'][idx])\n",
    "        label_value = self.dataset['label'][idx]\n",
    "        label = torch.tensor(label_value).long()\n",
    "        return image1, image2, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbeca8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShopeeImagePairDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file: 'shopee-data/merged_with_data_tensors.csv'\n",
    "            root_dir (string): Directory with all the images: 'shopee-data/train_images'\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img1_path = os.path.join(self.root_dir, self.dataframe['image_1'][idx])\n",
    "        img2_path = os.path.join(self.root_dir, self.dataframe['image_2'][idx])\n",
    "        \n",
    "        image1 = self.transform(img1_path)\n",
    "        image2 = self.transform(img2_path)\n",
    "        \n",
    "        label = torch.tensor(self.dataframe['label'][idx])\n",
    "        return image1, image2, label.int()\n",
    "    \n",
    "    def transform(self, image_path):\n",
    "        image = io.imread(image_path)\n",
    "        dim = (200, 200)\n",
    "        resized = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
    "        tran = transforms.ToTensor()  # Convert the numpy array (C, H, W) Tensor format and /255 normalize to [0, 1.0]\n",
    "        img_tensor = tran(resized) # (C,H,W), channel order (B, G, R)\n",
    "        return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3581f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'#'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "image_path = path + '/merged_with_data_tensors.csv'\n",
    "shopee_dataset = ShopeeImageDataset(image_path)\n",
    "batch_size = 4\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(shopee_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(shopee_dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(shopee_dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)\n",
    "print(len(train_loader))\n",
    "print(len(validation_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7490217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# training and validation loss were calculated after every epoch\n",
    "def train(model, train_loader, val_loader, num_epochs):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    cur_step = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        print(\"Starting epoch \" + str(epoch+1))\n",
    "        for i, data in enumerate(train_loader,0):\n",
    "            img0, img1, label = data\n",
    "            img0, img1, label = img0.to(device), img1.to(device) , label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "             # Forward\n",
    "            target = model(img0,img1)  \n",
    "            target = target.squeeze(1)\n",
    "            loss = criterion(target, label.float())\n",
    "            \n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_running_loss = 0.0\n",
    "        \n",
    "        #check validation loss after every epoch\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for i, data in enumerate(val_loader,0):\n",
    "                img1, img2, label = data\n",
    "                img1 = img1.to(device)\n",
    "                img2 = img2.to(device)\n",
    "                label = label.to(device)       \n",
    "                target = model(img1,img2)  \n",
    "                target = target.squeeze(1)\n",
    "                loss = criterion(target, label.float())\n",
    "                val_running_loss += loss.item()\n",
    "                ps = torch.exp(target)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                \n",
    "        avg_val_loss = val_running_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "        print('Epoch [{}/{}],Train Loss: {:.4f}, Valid Loss: {:.8f}'\n",
    "            .format(epoch+1, num_epochs, avg_train_loss, avg_val_loss))\n",
    "    print(\"Finished Training\")  \n",
    "    return train_losses, val_losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e824649",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShopeeImageNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ShopeeImageNet, self).__init__()\n",
    "        \n",
    "        # Conv2d(input_channels, output_channels, kernel_size)\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3) \n",
    "        self.conv2 = nn.Conv2d(64, 128, 3)  \n",
    "        self.conv3 = nn.Conv2d(128, 128, 3)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(256 * 21 * 21, 200)\n",
    "        self.fcOut = nn.Linear(200, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def convs(self, x): \n",
    "        #32, 3, 200, 200\n",
    "#         print(1, x.shape)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        # 32, 64, 198, 198\n",
    "#         print(2, x.shape)\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "#         print(3, x.shape)\n",
    "        # 32, 64, 99, 99\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "#         print(4, x.shape)\n",
    "        # 32, 128, 97, 97\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "#         print(5, x.shape)\n",
    "        # 32, 128, 48, 48\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "#         print(6, x.shape)\n",
    "        # 32, 128, 46, 46\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "#         print(7, x.shape)\n",
    "        # 32, 128, 23, 23\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "#         print(8, x.shape)\n",
    "        # 32, 256, 21, 21\n",
    "        return x\n",
    "\n",
    "    def forward(self, x1, x2):        \n",
    "        x1 = self.convs(x1)\n",
    "#         print('forward')\n",
    "#         print(9, x1.shape)\n",
    "        x1 = x1.view(-1, 256 * 21 * 21)\n",
    "#         print(10, x1.shape)\n",
    "        x1 = self.sigmoid(self.fc1(x1))\n",
    "#         print(11, x1.shape)\n",
    "        x2 = self.convs(x2)\n",
    "#         print(12, x2.shape)\n",
    "        x2 = x2.view(-1, 256 * 21 * 21)\n",
    "#         print(13, x2.shape)\n",
    "        x2 = self.sigmoid(self.fc1(x2))\n",
    "#         print(14, x2.shape)\n",
    "        x = torch.abs(x1 - x2)\n",
    "        x = self.fcOut(x)\n",
    "#         print(15, x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d1d5ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SiameseNetwork(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SiameseNetwork, self).__init__()\n",
    "#         self.cnn1 = nn.Sequential(\n",
    "#             nn.ReflectionPad2d(1),\n",
    "#             nn.Conv2d(3, 4, kernel_size=3),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.BatchNorm2d(4),\n",
    "            \n",
    "#             nn.ReflectionPad2d(1),\n",
    "#             nn.Conv2d(4, 8, kernel_size=3),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.BatchNorm2d(8),\n",
    "\n",
    "\n",
    "#             nn.ReflectionPad2d(1),\n",
    "#             nn.Conv2d(8, 8, kernel_size=3),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.BatchNorm2d(8),\n",
    "\n",
    "#         )\n",
    "\n",
    "#         self.fc1 = nn.Sequential(\n",
    "#             nn.Linear(8*100*100, 500),\n",
    "#             nn.ReLU(inplace=True),\n",
    "\n",
    "#             nn.Linear(500, 500),\n",
    "#             nn.ReLU(inplace=True),\n",
    "\n",
    "#             nn.Linear(500, 5))\n",
    "\n",
    "#     def forward_once(self, x):\n",
    "#         print(1, x.shape)\n",
    "#         output = self.cnn1(x)\n",
    "#         print(2, output.shape)\n",
    "#         output = output.view(output.size()[0], -1)\n",
    "#         print(3, output.shape)\n",
    "#         output = self.fc1(output)\n",
    "#         print(4, output.shape)\n",
    "#         return output\n",
    "\n",
    "#     def forward(self, input1, input2):\n",
    "#         output1 = self.forward_once(input1)\n",
    "#         output2 = self.forward_once(input2)\n",
    "#         return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b22dc708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Epoch [1/15],Train Loss: 0.6877, Valid Loss: 0.67333959\n",
      "Starting epoch 2\n",
      "Epoch [2/15],Train Loss: 0.5189, Valid Loss: 0.56731595\n",
      "Starting epoch 3\n",
      "Epoch [3/15],Train Loss: 0.4340, Valid Loss: 0.50313544\n",
      "Starting epoch 4\n",
      "Epoch [4/15],Train Loss: 0.3956, Valid Loss: 0.49347380\n",
      "Starting epoch 5\n",
      "Epoch [5/15],Train Loss: 0.3480, Valid Loss: 0.50378957\n",
      "Starting epoch 6\n",
      "Epoch [6/15],Train Loss: 0.3445, Valid Loss: 0.47681679\n",
      "Starting epoch 7\n",
      "Epoch [7/15],Train Loss: 0.3222, Valid Loss: 0.43339978\n",
      "Starting epoch 8\n",
      "Epoch [8/15],Train Loss: 0.2988, Valid Loss: 0.41472725\n",
      "Starting epoch 9\n",
      "Epoch [9/15],Train Loss: 0.2602, Valid Loss: 0.44721632\n",
      "Starting epoch 10\n",
      "Epoch [10/15],Train Loss: 0.2555, Valid Loss: 0.43940586\n",
      "Starting epoch 11\n",
      "Epoch [11/15],Train Loss: 0.2549, Valid Loss: 0.43719989\n",
      "Starting epoch 12\n",
      "Epoch [12/15],Train Loss: 0.2162, Valid Loss: 0.43533286\n",
      "Starting epoch 13\n",
      "Epoch [13/15],Train Loss: 0.2006, Valid Loss: 0.42871889\n",
      "Starting epoch 14\n",
      "Epoch [14/15],Train Loss: 0.1843, Valid Loss: 0.39703057\n",
      "Starting epoch 15\n",
      "Epoch [15/15],Train Loss: 0.1754, Valid Loss: 0.42330578\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.687726399073234,\n",
       "  0.518912217937983,\n",
       "  0.4339963117471108,\n",
       "  0.39564528373571545,\n",
       "  0.3480041812245662,\n",
       "  0.3445183098889314,\n",
       "  0.322186641395092,\n",
       "  0.29884947205965334,\n",
       "  0.2602346489349237,\n",
       "  0.25550638368496525,\n",
       "  0.2548892629834322,\n",
       "  0.21621090918779373,\n",
       "  0.2006189587454383,\n",
       "  0.18425898966737664,\n",
       "  0.17538555338978767],\n",
       " [0.6733395883015224,\n",
       "  0.5673159531184605,\n",
       "  0.5031354427337646,\n",
       "  0.4934737980365753,\n",
       "  0.5037895696503776,\n",
       "  0.4768167861870357,\n",
       "  0.433399783713477,\n",
       "  0.4147272514445441,\n",
       "  0.44721631918634686,\n",
       "  0.43940586277416777,\n",
       "  0.4371998906135559,\n",
       "  0.4353328560079847,\n",
       "  0.42871889046260286,\n",
       "  0.3970305749348232,\n",
       "  0.42330577969551086])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ShopeeImageNet().to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "train(net, train_loader, validation_loader, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21054c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Epoch [1/15],Train Loss: 0.1751, Valid Loss: 0.44071536\n",
      "Starting epoch 2\n",
      "Epoch [2/15],Train Loss: 0.1555, Valid Loss: 0.41064913\n",
      "Starting epoch 3\n",
      "Epoch [3/15],Train Loss: 0.1359, Valid Loss: 0.39049576\n",
      "Starting epoch 4\n",
      "Epoch [4/15],Train Loss: 0.1169, Valid Loss: 0.43083871\n",
      "Starting epoch 5\n",
      "Epoch [5/15],Train Loss: 0.0807, Valid Loss: 0.40189452\n",
      "Starting epoch 6\n",
      "Epoch [6/15],Train Loss: 0.0665, Valid Loss: 0.30421914\n",
      "Starting epoch 7\n",
      "Epoch [7/15],Train Loss: 0.0741, Valid Loss: 0.48520387\n",
      "Starting epoch 8\n",
      "Epoch [8/15],Train Loss: 0.0615, Valid Loss: 0.46693171\n",
      "Starting epoch 9\n",
      "Epoch [9/15],Train Loss: 0.0453, Valid Loss: 0.43519041\n",
      "Starting epoch 10\n",
      "Epoch [10/15],Train Loss: 0.0449, Valid Loss: 0.49608188\n",
      "Starting epoch 11\n",
      "Epoch [11/15],Train Loss: 0.0313, Valid Loss: 0.45900984\n",
      "Starting epoch 12\n",
      "Epoch [12/15],Train Loss: 0.0420, Valid Loss: 0.42668013\n",
      "Starting epoch 13\n",
      "Epoch [13/15],Train Loss: 0.0281, Valid Loss: 0.43372375\n",
      "Starting epoch 14\n",
      "Epoch [14/15],Train Loss: 0.0384, Valid Loss: 0.40528557\n",
      "Starting epoch 15\n",
      "Epoch [15/15],Train Loss: 0.0365, Valid Loss: 0.41594523\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.1751433229073882,\n",
       "  0.15554157042732605,\n",
       "  0.13594171016190487,\n",
       "  0.11685600855316107,\n",
       "  0.08072082773567392,\n",
       "  0.06648098999777666,\n",
       "  0.07409354725566047,\n",
       "  0.061485446219404154,\n",
       "  0.045321206199542545,\n",
       "  0.044925578646003626,\n",
       "  0.03127374560258781,\n",
       "  0.04195188661105931,\n",
       "  0.028055404859165158,\n",
       "  0.038401840174069196,\n",
       "  0.03652631083521275],\n",
       " [0.44071535978998455,\n",
       "  0.41064912719385965,\n",
       "  0.39049576435770306,\n",
       "  0.43083871262414114,\n",
       "  0.4018945183072771,\n",
       "  0.3042191434651613,\n",
       "  0.4852038707051958,\n",
       "  0.4669317070926939,\n",
       "  0.4351904051644461,\n",
       "  0.49608188228947775,\n",
       "  0.45900984161666464,\n",
       "  0.4266801306179592,\n",
       "  0.4337237541164671,\n",
       "  0.4052855691739491,\n",
       "  0.4159452276570456])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "train(net, train_loader, validation_loader, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17e364d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Epoch [1/15],Train Loss: 0.6623, Valid Loss: 0.50611464\n",
      "Starting epoch 2\n",
      "Epoch [2/15],Train Loss: 0.6016, Valid Loss: 0.51797582\n",
      "Starting epoch 3\n",
      "Epoch [3/15],Train Loss: 0.6087, Valid Loss: 0.48111221\n",
      "Starting epoch 4\n",
      "Epoch [4/15],Train Loss: 0.6440, Valid Loss: 0.49286142\n",
      "Starting epoch 5\n",
      "Epoch [5/15],Train Loss: 0.6840, Valid Loss: 0.46513806\n",
      "Starting epoch 6\n",
      "Epoch [6/15],Train Loss: 0.6602, Valid Loss: 0.48601155\n",
      "Starting epoch 7\n",
      "Epoch [7/15],Train Loss: 0.6020, Valid Loss: 0.40842569\n",
      "Starting epoch 8\n",
      "Epoch [8/15],Train Loss: 0.6171, Valid Loss: 0.37595067\n",
      "Starting epoch 9\n",
      "Epoch [9/15],Train Loss: 0.6199, Valid Loss: 0.45864494\n",
      "Starting epoch 10\n",
      "Epoch [10/15],Train Loss: 0.6132, Valid Loss: 0.47319835\n",
      "Starting epoch 11\n",
      "Epoch [11/15],Train Loss: 0.5801, Valid Loss: 0.52701383\n",
      "Starting epoch 12\n",
      "Epoch [12/15],Train Loss: 0.6115, Valid Loss: 0.42323677\n",
      "Starting epoch 13\n",
      "Epoch [13/15],Train Loss: 0.5766, Valid Loss: 0.62392559\n",
      "Starting epoch 14\n",
      "Epoch [14/15],Train Loss: 0.6186, Valid Loss: 0.49646799\n",
      "Starting epoch 15\n",
      "Epoch [15/15],Train Loss: 0.5615, Valid Loss: 0.41553084\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.6622893740781225,\n",
       "  0.6016094420964901,\n",
       "  0.6087492681466616,\n",
       "  0.644046235543031,\n",
       "  0.6840481483019315,\n",
       "  0.6601663203193591,\n",
       "  0.6020230295566412,\n",
       "  0.6170969909200301,\n",
       "  0.6199173285410955,\n",
       "  0.6131548308409177,\n",
       "  0.5801070773830781,\n",
       "  0.6114575094901599,\n",
       "  0.576627946816958,\n",
       "  0.6186155241269332,\n",
       "  0.5615347142402942],\n",
       " [0.5061146361487252,\n",
       "  0.5179758157048907,\n",
       "  0.48111221407141,\n",
       "  0.49286141778741566,\n",
       "  0.4651380607060024,\n",
       "  0.4860115477016994,\n",
       "  0.4084256887435913,\n",
       "  0.37595067279679434,\n",
       "  0.45864494144916534,\n",
       "  0.47319834785802023,\n",
       "  0.5270138340336936,\n",
       "  0.4232367681605475,\n",
       "  0.6239255879606519,\n",
       "  0.4964679905346462,\n",
       "  0.41553084339414326])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "train(net, train_loader, validation_loader, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1fa692a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Epoch [1/15],Train Loss: 0.5687, Valid Loss: 0.50100323\n",
      "Starting epoch 2\n",
      "Epoch [2/15],Train Loss: 0.5553, Valid Loss: 0.56828134\n",
      "Starting epoch 3\n",
      "Epoch [3/15],Train Loss: 0.5140, Valid Loss: 0.47692915\n",
      "Starting epoch 4\n",
      "Epoch [4/15],Train Loss: 0.5679, Valid Loss: 0.42278424\n",
      "Starting epoch 5\n",
      "Epoch [5/15],Train Loss: 0.5538, Valid Loss: 0.54363891\n",
      "Starting epoch 6\n",
      "Epoch [6/15],Train Loss: 0.5400, Valid Loss: 0.43242516\n",
      "Starting epoch 7\n",
      "Epoch [7/15],Train Loss: 0.6109, Valid Loss: 0.56211643\n",
      "Starting epoch 8\n",
      "Epoch [8/15],Train Loss: 0.6179, Valid Loss: 0.66982604\n",
      "Starting epoch 9\n",
      "Epoch [9/15],Train Loss: 0.7160, Valid Loss: 0.53676099\n",
      "Starting epoch 10\n",
      "Epoch [10/15],Train Loss: 0.6780, Valid Loss: 0.60681472\n",
      "Starting epoch 11\n",
      "Epoch [11/15],Train Loss: 0.7104, Valid Loss: 0.44662353\n",
      "Starting epoch 12\n",
      "Epoch [12/15],Train Loss: 0.6693, Valid Loss: 0.47479344\n",
      "Starting epoch 13\n",
      "Epoch [13/15],Train Loss: 0.6031, Valid Loss: 0.47811382\n",
      "Starting epoch 14\n",
      "Epoch [14/15],Train Loss: 0.5504, Valid Loss: 0.39480319\n",
      "Starting epoch 15\n",
      "Epoch [15/15],Train Loss: 0.4519, Valid Loss: 0.31454537\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.5686799677518698,\n",
       "  0.5552784066933852,\n",
       "  0.5139550205606681,\n",
       "  0.5678679530437176,\n",
       "  0.5538326605008199,\n",
       "  0.5400155438826635,\n",
       "  0.6109110071108892,\n",
       "  0.6179086886919462,\n",
       "  0.7159804896666453,\n",
       "  0.6780402832306348,\n",
       "  0.7103562068480712,\n",
       "  0.6693481734165778,\n",
       "  0.6030816023166363,\n",
       "  0.5504048415101491,\n",
       "  0.451857885489097],\n",
       " [0.5010032270635877,\n",
       "  0.5682813440050397,\n",
       "  0.4769291451999119,\n",
       "  0.42278424331120085,\n",
       "  0.5436389063085828,\n",
       "  0.43242516262190683,\n",
       "  0.5621164270809719,\n",
       "  0.6698260392461505,\n",
       "  0.5367609901087624,\n",
       "  0.6068147165434701,\n",
       "  0.4466235339641571,\n",
       "  0.47479343840054106,\n",
       "  0.47811382157461985,\n",
       "  0.39480319193431307,\n",
       "  0.31454537117055487])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.005)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "train(net, train_loader, validation_loader, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cc0722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
